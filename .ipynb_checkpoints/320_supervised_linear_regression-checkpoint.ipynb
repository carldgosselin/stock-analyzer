{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5caafff70ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mshow_supervised_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5caafff70ee3>\u001b[0m in \u001b[0;36mshow_supervised_linear_regression\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Plot outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carldgosselin/anaconda/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0m_center_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carldgosselin/anaconda/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    140\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m/Users/carldgosselin/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[1;32m    358\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[1;32m    359\u001b[0m                              \u001b[0;34m\" minimum of %d is required.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                              % (n_samples, shape_repr, ensure_min_samples))\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as spo\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def symbol_to_path(symbol, base_dir=\"data\"):\n",
    "    return os.path.join(base_dir, \"{}.csv\".format(str(symbol)))\n",
    "\n",
    "def plot_selected(df, columns, start_index, end_index):\n",
    "    plot_data(df.ix[start_index:end_index,columns], title=\"Stock Data\")\n",
    "       \n",
    "def plot_data(df, title):\n",
    "    ax = df.plot(title=title,fontsize=12,figsize=(12,10))\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "def show_supervised_linear_regression():\n",
    "    \n",
    "    df = pd.read_csv(symbol_to_path('SPY'), index_col='Date', \n",
    "                parse_dates=True, \n",
    "                usecols=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'], \n",
    "                na_values=['nan'])\n",
    "    \n",
    "    # sort data chronologically\n",
    "    df = df.sort_index(ascending=True, axis=0)\n",
    "    \n",
    "    # add new column to view Adj Close 5 days later\n",
    "    df['Adj_Close_5_Days_Later'] = df['Adj Close']\n",
    "    df['Adj_Close_5_Days_Later'] = df['Adj_Close_5_Days_Later'].shift(-5)\n",
    "    \n",
    "    X_train = df.iloc[0:1000,:-1]\n",
    "    y_train = df.iloc[0:1000, -1]\n",
    "    # X_test = df.iloc[1000:1253,:-1]\n",
    "    # y_test = df.iloc[1000:1253, -1]\n",
    "    X_test = df.iloc[1252:1253,:-1]\n",
    "    y_test = df.iloc[1252:1253, -1]\n",
    "    \n",
    "    \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "    \n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    # Query\n",
    "    regr.predict(X_test)\n",
    "    \n",
    "    # Plot outputs\n",
    "    print \"\\n\"\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.title(\"Actual results vs machine learning predictions\")\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Actual result\")\n",
    "    plt.scatter(regr.predict(X_test), y_test, color='blue')\n",
    "    plt.show()\n",
    "    \n",
    "    # Explained variance score: 1 is perfect\n",
    "    # Score\n",
    "    print \"Score on training data\"\n",
    "    print \"regr.score(X_train, y_train): \", regr.score(X_train, y_train), \"\\n\"\n",
    "    \n",
    "    print \"Score on testing (unseen) data\"\n",
    "    print('regr.score(X_test, y_test): %.2f' % regr.score(X_test, y_test))\n",
    "    # The mean square error\n",
    "    print \"Mean squared error: \", mean_squared_error(y_test, regr.predict(X_test)), \"\\n\"\n",
    "    \n",
    "    print \"\\n\"\n",
    "    print \"Prediction: \"\n",
    "    print regr.predict(X_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    show_supervised_linear_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
